import os
import typer
import asyncio
from typing import Annotated
from rich.console import Console
from dotenv import load_dotenv
from langchain_openai import AzureChatOpenAI, ChatOpenAI
from langgraph.prebuilt import create_react_agent
from langchain_core.tools import tool
from pydantic import SecretStr

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

console = Console()
app = typer.Typer()

@tool
def get_current_time():
    """ç¾åœ¨ã®æ™‚åˆ»ã‚’å–å¾—ã—ã¾ã™ã€‚"""
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

@tool
def calculator(expression: str) -> str:
    """ç°¡å˜ãªæ•°å¼ã‚’è¨ˆç®—ã—ã¾ã™ã€‚ä¾‹: '2 + 3' -> '5'"""
    try:
        result = eval(expression)
        return str(result)
    except Exception as e:
        return f"è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}"

async def send_message(message: str) -> None:
    """
    LangGraphã®ReActã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™
    """
    # USE_AZUREç’°å¢ƒå¤‰æ•°ã§ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’æ±ºå®š
    use_azure = os.getenv("USE_AZURE", "false").lower() == "true"
    
    if use_azure:
        # Azure OpenAI APIã®ç’°å¢ƒå¤‰æ•°ç¢ºèª
        required_vars = ["AZURE_OPENAI_API_KEY", "AZURE_ENDPOINT", "AZURE_OPENAI_API_DEPLOYMENT_ID"]
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        
        if missing_vars:
            console.print(f"[red]ã‚¨ãƒ©ãƒ¼: ä»¥ä¸‹ã®Azure OpenAIç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“: {', '.join(missing_vars)}[/red]")
            return
    else:
        # OpenAI APIã®ç’°å¢ƒå¤‰æ•°ç¢ºèª
        required_vars = ["OPENAI_API_KEY"]
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        
        if missing_vars:
            console.print(f"[red]ã‚¨ãƒ©ãƒ¼: ä»¥ä¸‹ã®OpenAIç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“: {', '.join(missing_vars)}[/red]")
            return
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®è¡¨ç¤º
    if use_azure:
        console.print("[dim]Azure OpenAIè¨­å®š:[/dim]")
        console.print(f"[dim]  ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: {os.getenv('AZURE_ENDPOINT')}[/dim]")
        console.print(f"[dim]  ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ: {os.getenv('AZURE_OPENAI_API_DEPLOYMENT_ID')}[/dim]")
        console.print(f"[dim]  APIãƒãƒ¼ã‚¸ãƒ§ãƒ³: {os.getenv('AZURE_OPENAI_API_VERSION', '2024-10-21')}[/dim]")
    else:
        console.print("[dim]OpenAIè¨­å®š:[/dim]")
        console.print(f"[dim]  ãƒ¢ãƒ‡ãƒ«: {os.getenv('LLM_MODEL', 'gpt-4o')}[/dim]")
    console.print()
    
    # LLMã¨ãƒ„ãƒ¼ãƒ«ã®è¨­å®š
    if use_azure:
        llm = AzureChatOpenAI(
            model=os.getenv("LLM_MODEL", "gpt-4o"),
            api_key=SecretStr(os.getenv("AZURE_OPENAI_API_KEY", "")) or None,
            azure_endpoint=os.getenv("AZURE_ENDPOINT"),
            azure_deployment=os.getenv("AZURE_OPENAI_API_DEPLOYMENT_ID"),
            api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2024-10-21"),
            temperature=0,
            streaming=True
        )
    else:
        llm = ChatOpenAI(
            model=os.getenv("LLM_MODEL", "gpt-4o"),
            api_key=SecretStr(os.getenv("OPENAI_API_KEY", "")) or None,
            temperature=0,
            streaming=True
        )
    tools = [get_current_time, calculator]
    
    # ReActã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæˆ
    agent = create_react_agent(llm, tools)
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‡¦ç†
    console.print("[cyan]ğŸ¤– ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ€è€ƒä¸­...[/cyan]\n")
    
    response_started = False
    
    try:
        async for event in agent.astream_events({"messages": [("user", message)]}, version="v1"):
            # ãƒ‡ãƒãƒƒã‚°: ã™ã¹ã¦ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒ­ã‚°å‡ºåŠ›
            # console.print(f"[dim]DEBUG: {event.get('event', 'unknown')}[/dim]")
            
            # ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†
            if event.get("event") == "on_chat_model_stream":
                chunk = event["data"].get("chunk")
                if chunk and hasattr(chunk, "content") and chunk.content:
                    if not response_started:
                        console.print("[green]ğŸ¤– å›ç­”:[/green]")
                        response_started = True
                    console.print(chunk.content, end="")
            
            # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œé–‹å§‹ã‚¤ãƒ™ãƒ³ãƒˆ
            elif event.get("event") == "on_tool_start":
                tool_name = event.get("name", "unknown")
                tool_input = event["data"].get("input", {})
                console.print(f"\n[blue]ğŸ”§ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œä¸­: {tool_name}({tool_input})[/blue]")
            
            # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµ‚äº†ã‚¤ãƒ™ãƒ³ãƒˆ
            elif event.get("event") == "on_tool_end":
                tool_name = event.get("name", "unknown")
                tool_output = event["data"].get("output", "")
                console.print(f"[yellow]âœ… ãƒ„ãƒ¼ãƒ«çµæœ: {tool_output}[/yellow]")
        
        if response_started:
            console.print()  # æœ€å¾Œã«æ”¹è¡Œ
        console.print(f"[green]âœ… å®Œäº†[/green]")
    
    except Exception as e:
        console.print(f"[red]ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}[/red]")


@app.command()
def send(
    message: Annotated[str, typer.Argument(help="é€ä¿¡ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")]
):
    """
    ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã™ã‚‹CLIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    """
    asyncio.run(send_message(message))

@app.command()
def mock(message: str):
    """
    GUIã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã™ã‚‹é–¢æ•°
    """
    console.print(f"[green]ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã—ã¾ã—ãŸ: {message}[/green]")


if __name__ == "__main__":
    # CLIãƒ¢ãƒ¼ãƒ‰ã¨ã—ã¦å®Ÿè¡Œ
    print("CLIãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œä¸­...")
    app()
